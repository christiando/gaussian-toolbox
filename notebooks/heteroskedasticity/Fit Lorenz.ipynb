{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348be8c8-8a82-4cbe-b42e-e724efae794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "sys.path.append('../../timeseries/')\n",
    "sys.path.append('../../timeseries/experiments_scripts/')\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "import factor\n",
    "import state_models\n",
    "import observation_models\n",
    "from ssm_em import StateSpaceEM\n",
    "from nonlinear_ssm import NonLinearStateSpace_EM\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import zscore\n",
    "from ssm_em import StateSpaceEM, load_model\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.gaussian_process.kernels import ExpSineSquared, RBF\n",
    "\n",
    "from exp_utils import *\n",
    "import ssm\n",
    "\n",
    "'''\n",
    "sys.path.append('../../timeseries/kalman-jax-master')\n",
    "from jax.experimental import optimizers\n",
    "#from sde_gp import SDEGP\n",
    "import approximate_inference as approx_inf\n",
    "import priors\n",
    "import likelihoods\n",
    "from utils import softplus_list, plot\n",
    "'''\n",
    "\n",
    "\n",
    "class PredictiveDensity:\n",
    "    def __init__(self, mu, sigma):\n",
    "        if mu.ndim == 1:\n",
    "            self.mu = np.array([mu]).T\n",
    "        else:\n",
    "            self.mu = np.array(mu)\n",
    "        if sigma.ndim == 1:\n",
    "            self.Sigma = np.array([sigma]).T\n",
    "        else:    \n",
    "            self.Sigma = np.array(sigma)\n",
    "            \n",
    "def reset_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "def train_linear_SSM(x_tr, dz, init_w_pca=False, smooth_window=20):\n",
    "\n",
    "    dx = x_tr.shape[1]\n",
    "    sm = state_models.LinearStateModel(dz)\n",
    "    om = observation_models.LinearObservationModel(dx, dz, noise_x=1.)\n",
    "    \n",
    "    if init_w_pca == 1:\n",
    "        om.pca_init(x_tr, smooth_window=smooth_window)\n",
    "        \n",
    "    ssm_em_lin = StateSpaceEM(x_tr, observation_model=om, state_model=sm)\n",
    "    ssm_em_lin.run()\n",
    "    \n",
    "    return ssm_em_lin\n",
    "\n",
    "\n",
    "def train_linear_hsk_SSM(x_tr, dz, du, init_w_pca=False, smooth_window=20):\n",
    "\n",
    "    dx = x_tr.shape[1]\n",
    "    sm_hs = state_models.LinearStateModel(dz)\n",
    "    om_hs = observation_models.HCCovObservationModel(dx, dz, du)\n",
    "    if init_w_pca == 1:\n",
    "        om_hs.pca_init(x_tr, smooth_window=20)\n",
    "    hs_model = StateSpaceEM(x_tr, observation_model=om_hs, state_model=sm_hs, conv_crit=1e-4)\n",
    "    hs_model.run()\n",
    "    \n",
    "    return hs_model\n",
    "\n",
    "def train_nonlinear_SSM(x_tr, **kwargs):\n",
    "    '''\n",
    "    to be updated; currently doesn't run\n",
    "    LSEMStateModel -> sm_hs = state_models.LSEMStateModel(args.dz,args.dk# + param for basis func)\n",
    "    '''\n",
    "    nonlin_model = NonLinearStateSpace_EM(x_tr,args.dz, args.dk)\n",
    "    nonlin_model.run()\n",
    "    \n",
    "    return nonlin_model\n",
    "\n",
    "class HMM_class:\n",
    "    \n",
    "    def __init__(self, x_tr, K, obs_model='gaussian'):\n",
    "        self.x_tr = x_tr\n",
    "        self.D = x_tr.shape[1]\n",
    "        self.K = K\n",
    "        self.obs_model = obs_model\n",
    "        self.model = self._train()\n",
    "        \n",
    "    def _train(self):\n",
    "        model = ssm.HMM(self.K, self.D, observations=self.obs_model)\n",
    "        model.fit(self.x_tr, method=\"em\")\n",
    "        return model\n",
    "\n",
    "    def compute_predictive_log_likelihood(self, x_te):\n",
    "        return self.model.log_likelihood(x_te)\n",
    "    \n",
    "    def compute_predictive_density(self, x_te):\n",
    "        mask = np.logical_not(np.isnan(x_te))\n",
    "        x_te_not_nan = np.zeros(x_te.shape)\n",
    "        x_te_not_nan[mask] = x_te[mask]\n",
    "        states = self.model.filter(x_te_not_nan, mask=mask)\n",
    "        if self.obs_model == 'gaussian' or  self.obs_model == 'studentst':\n",
    "            mean_te = np.dot(states, self.model.observations.mus)\n",
    "        elif self.obs_model == 'ar':\n",
    "            mean_te = np.sum(states[:,:,None] * (np.sum(self.model.observations.As[None] * x_te[:,None, None], axis=3) + self.model.observations.bs), axis=1)\n",
    "        std_te = np.dot(states, np.sqrt(self.model.observations.Sigmas.diagonal(axis1=1, axis2=2)))\n",
    "        print(mean_te.shape, std_te.shape)\n",
    "        return PredictiveDensity(mean_te, std_te ** 2)\n",
    "\n",
    "def train_HMM(x_tr, num_states, **kwargs):\n",
    "    return HMM_class(x_tr, num_states)\n",
    "\n",
    "\n",
    "class ARIMAX:\n",
    "    \n",
    "    def __init__(self, x_tr, p, q):\n",
    "        self.x_tr = x_tr\n",
    "        self.p = p_arimax\n",
    "        self.q = q_arimax\n",
    "        self._train()\n",
    "        \n",
    "    def _train(self):\n",
    "        if x_tr.shape[1] == 1:\n",
    "            self.mod = sm.tsa.statespace.SARIMAX(x_tr, trend='c', order=(self.p,0,self.q))\n",
    "            self.fit_res = self.mod.fit(disp=False)\n",
    "        else:\n",
    "            self.mod = sm.tsa.VARMAX(x_tr, trend='c', order=(self.p,self.q))\n",
    "            self.fit_res = self.mod.fit(disp=False, max_iter=1000)\n",
    "            \n",
    "    def compute_predictive_density(self, x_te):\n",
    "        mod_te = self.mod.clone(x_te)\n",
    "        res = mod_te.filter(self.fit_res.params)\n",
    "        predict = res.get_prediction()\n",
    "        predict_ci = predict.conf_int(alpha=1.-.68)\n",
    "        mu = predict.predicted_mean\n",
    "        if x_te.shape[1] == 1:\n",
    "            std = predict.predicted_mean - predict_ci[:,0]\n",
    "        else:\n",
    "            std = predict.predicted_mean - predict_ci[:,:x_te.shape[1]]\n",
    "        return PredictiveDensity(mu, std ** 2)\n",
    "            \n",
    "    def compute_predictive_log_likelihood(self, x_te):  \n",
    "        mod_te = self.mod.clone(x_te)\n",
    "        return mod_te.loglike(self.fit_res.params)\n",
    "    \n",
    "def train_arimax(x_tr, **kwargs):\n",
    "    \n",
    "    arimax_model = ARIMAX(x_tr)\n",
    "    return arimax_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d05157-cf5c-4c4b-b2ab-64c80f10b746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d53d06-bc46-4c25-96ee-3cfad10a9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c7d25-739e-4050-b71e-ae6e7f62f1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
