{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made for rechecking the lower bound of the heteroscedastic model.\n",
    "\n",
    "It shows that the lower bound works well, and that rather the model is a bit problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussian_toolbox import pdf, approximate_conditional\n",
    "import numpy as np \n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "from matplotlib import pyplot as plt\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "Dy = 3\n",
    "Dx = 1\n",
    "R = 1\n",
    "Du = 1\n",
    "\n",
    "M = jnp.array([jnp.eye(Dy)])[:, :, :Dx]\n",
    "b = jnp.array([jnp.zeros(Dy)])\n",
    "Sigma = jnp.array([jnp.eye(Dy)]) + .1\n",
    "mat = np.random.randn(Dy, Dy)\n",
    "Q, R = np.linalg.qr(mat)\n",
    "U = Q[:, :Du]\n",
    "W = jnp.array(np.random.randn(Du, Dx + 1))\n",
    "\n",
    "cond = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma, U=U, W=W)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if cosh is rightly implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.array([jnp.linspace(-5,5,100)]).T\n",
    "cosh_gt = cond.exp_h_minus(x) + cond.exp_h_plus(x)\n",
    "cosh_np = jnp.cosh((jnp.dot(W[:, 1:], x.T) + W[:, 0]))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, cosh_gt.T)\n",
    "plt.plot(x, cosh_np.T, '--')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(x, 1./cosh_gt.T)\n",
    "plt.plot(x, 1./cosh_np.T, '--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if covariance matrix is computed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_gt, prec_gt, ln_det_cov_gt = cond.get_conditional_cov(x, invert=True)\n",
    "plt.plot(x, jnp.sum(jnp.sum(jnp.abs(jnp.einsum('abc,acd->abd', cov_gt, prec_gt) - jnp.eye(Dy)[None]) / jnp.abs(cov_gt), axis=1), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_det_cov_np = jnp.linalg.slogdet(cov_gt)[1]\n",
    "plt.plot(jnp.abs(ln_det_cov_gt - ln_det_cov_np) / jnp.abs(ln_det_cov_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = cond.exp_h_minus(x) + cond.exp_h_plus(x) - 1.\n",
    "diag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_mat = jnp.eye(Dy) + jnp.einsum('abc,dc->abd', jnp.einsum('ab,ca->bca', diag, U), U)\n",
    "L = jnp.linalg.cholesky(Sigma)\n",
    "cov_mat_np = jnp.einsum('abc,adc->abd', jnp.einsum('abc,acd->abd', L, rot_mat), L)\n",
    "plt.plot(x, jnp.sum(jnp.sum(jnp.abs(cov_mat_np - cov_gt) / jnp.abs(cov_gt), axis=1), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = jnp.array(np.random.randn(100,Dy))\n",
    "plt.plot(cond(x).evaluate(y, element_wise=True), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random as jrand\n",
    "pX = pdf.GaussianPDF(mu=jnp.zeros(Dx)[None], Sigma=jnp.eye(Dx)[None])\n",
    "key = jrand.PRNGKey(0)\n",
    "x_samples = pX.sample(key, 10000)\n",
    "int_log_cond_y_np = jnp.mean(cond(x_samples[:,0]).evaluate_ln(y), axis=0)\n",
    "px = pdf.GaussianPDF(mu=jnp.tile(pX.mu, (100,1)), Sigma=jnp.tile(pX.Sigma, (100,1,1)))\n",
    "int_log_cond_y_gt = cond.integrate_log_conditional_y(p_x=px, y= y)\n",
    "\n",
    "plt.plot(int_log_cond_y_np, int_log_cond_y_gt, '.')\n",
    "plt.plot([jnp.amin(jnp.stack([int_log_cond_y_gt, int_log_cond_y_np])),jnp.amax(jnp.stack([int_log_cond_y_gt, int_log_cond_y_np]))], \n",
    "         [jnp.amin(jnp.stack([int_log_cond_y_gt, int_log_cond_y_np])),jnp.amax(jnp.stack([int_log_cond_y_gt, int_log_cond_y_np]))], '--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check log determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import lax\n",
    "import jax\n",
    "\n",
    "ln_det_cov_gt_arr = np.zeros(50)\n",
    "ln_det_cov_np_arr = np.zeros(50)\n",
    "\n",
    "for i in range(50):\n",
    "    M = jnp.array([jnp.eye(Dy)])\n",
    "    b = jnp.array([jnp.zeros(Dy)])\n",
    "    Sigma = jnp.array([jnp.eye(Dy)]) + .1\n",
    "    mat = np.random.randn(Dy, Dy)\n",
    "    Q, R = np.linalg.qr(mat)\n",
    "    U = Q[:, :Du]\n",
    "    W = jnp.array(np.random.randn(Du, Dx + 1))\n",
    "\n",
    "    cond = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma, U=U, W=W)\n",
    "\n",
    "    pX = pdf.GaussianPDF(mu=jnp.zeros(Dx)[None], Sigma=jnp.eye(Dx)[None])\n",
    "    ln_det_cov_np = jnp.mean(cond(x_samples[:,0]).ln_det_Sigma)\n",
    "    def scan_body_function(carry, args_i):\n",
    "        W_i, u_i = args_i\n",
    "        omega_star_i, omega_dagger_i, _ = lax.stop_gradient(\n",
    "            cond._get_omega_star_i(W_i, u_i, px, y)\n",
    "        )\n",
    "        uRu_i, log_lb_sum_i = cond._get_lb_i(\n",
    "            W_i, u_i, omega_star_i, omega_dagger_i, px, y\n",
    "        )\n",
    "        result = (uRu_i, log_lb_sum_i)\n",
    "        return carry, result\n",
    "\n",
    "    _, result = lax.scan(scan_body_function, None, (cond.W, cond.U.T))\n",
    "    uRu, log_lb_sum = result\n",
    "    ln_det_cov_gt = log_lb_sum + cond.ln_det_Sigma\n",
    "    ln_det_cov_gt_arr[i] = ln_det_cov_gt[0,0]\n",
    "    ln_det_cov_np_arr[i] = ln_det_cov_np\n",
    "#assert jnp.alltrue(jnp.less_equal(ln_det_cov_np_arr, ln_det_cov_gt_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ln_det_cov_np_arr, ln_det_cov_gt_arr, '.')\n",
    "plt.plot([jnp.amin(jnp.stack([ln_det_cov_gt_arr, ln_det_cov_np_arr])),jnp.amax(jnp.stack([ln_det_cov_gt_arr, ln_det_cov_np_arr]))],\n",
    "            [jnp.amin(jnp.stack([ln_det_cov_gt_arr, ln_det_cov_np_arr])),jnp.amax(jnp.stack([ln_det_cov_gt_arr, ln_det_cov_np_arr]))], '--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check quadratic term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = cond.get_conditional_mu(x_samples[:,0])[0]\n",
    "cov, prec, ln_det_cov_gt = cond.get_conditional_cov(x_samples[:,0], invert=True)\n",
    "mat = prec - jnp.linalg.inv(cond.Sigma)\n",
    "y_mu = y[None] - mu[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_np = jnp.mean(jnp.einsum('abc, abc->ab', jnp.einsum('abc,adc->adb', mat, y_mu), y_mu), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gt = -jnp.sum(uRu,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res_np, res_gt, '.')\n",
    "plt.plot([jnp.amin(jnp.stack([res_gt, res_np])),jnp.amax(jnp.stack([res_gt, res_np]))],\n",
    "         [jnp.amin(jnp.stack([res_gt, res_np])),jnp.amax(jnp.stack([res_gt, res_np]))], '--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check diagonal term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosh = cond.exp_h_minus(x_samples[:,0]) + cond.exp_h_plus(x_samples[:,0])\n",
    "G_np = jnp.mean((cosh-1)/cosh, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond._get_omega_star_i(W, U.T, px, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussian_toolbox import pdf, factor\n",
    "from jaxtyping import Array, Float\n",
    "from typing import Tuple\n",
    "\n",
    "def _get_G_i(\n",
    "        cond,\n",
    "        W_i: Float[Array, \"Dx+1\"],\n",
    "        u_i: Float[Array, \"Dy\"],\n",
    "        omega_star: Float[Array, \"N\"],\n",
    "        p_x: pdf.GaussianPDF,\n",
    "        y: Float[Array, \"N Dy\"],\n",
    "    ) -> Tuple[Float[Array, \"N\"], Float[Array, \"N\"]]:\n",
    "        # phi = pdf.GaussianPDF(**phi_dict)\n",
    "        # beta = self.beta[iu:iu + 1]\n",
    "        # Lower bound for \\mathbb{E}[ln (sigma_x^2 + f(h))]\n",
    "        G = p_x.R\n",
    "        w_i = W_i[1:].reshape((1, -1))\n",
    "        v = jnp.tile(w_i, (G, 1))\n",
    "        b_i = W_i[:1]\n",
    "        u_i = u_i.reshape((-1, 1))\n",
    "        # Lower bound for \\mathbb{E}[ln (sigma_x^2 + f(h))]\n",
    "        g_omega = cond.g(omega_star)\n",
    "        nu = -g_omega[:, None] * b_i * w_i\n",
    "        nu_plus = w_i + nu\n",
    "        nu_minus = -w_i + nu\n",
    "        f_omega_star = cond.f(omega_star)\n",
    "        ln_beta = -jnp.where(\n",
    "            jnp.isclose(f_omega_star, 0), 0, jnp.log(1 + f_omega_star)\n",
    "        ) - 0.5 * g_omega * (b_i**2 - omega_star**2)\n",
    "        ln_beta_plus = ln_beta + b_i - jnp.log(2)\n",
    "        ln_beta_minus = ln_beta - b_i - jnp.log(2)\n",
    "        # Create OneRankFactors\n",
    "        g_omega = jnp.clip(g_omega, a_min=1e-4)\n",
    "        exp_factor_plus = factor.OneRankFactor(\n",
    "            v=v, g=g_omega, nu=nu_plus, ln_beta=ln_beta_plus\n",
    "        )\n",
    "        exp_factor_minus = factor.OneRankFactor(\n",
    "            v=v, g=g_omega, nu=nu_minus, ln_beta=ln_beta_minus\n",
    "        )\n",
    "        one_factor = factor.OneRankFactor(v=v, g=g_omega, nu=nu, ln_beta=ln_beta)\n",
    "        # Create the two measures\n",
    "        exp_phi_plus = p_x.hadamard(exp_factor_plus, update_full=True)\n",
    "        exp_phi_minus = p_x.hadamard(exp_factor_minus, update_full=True)\n",
    "        phi_one = p_x.hadamard(one_factor, update_full=True)\n",
    "\n",
    "        mat1 = -cond.M[0]\n",
    "        vec1 = y - cond.b[0]\n",
    "        vec1_projected = jnp.einsum(\"ba,cb->ca\", cond.L_inv[0], vec1)\n",
    "        mat1_projected = jnp.einsum(\"ba,bc->ac\", cond.L_inv[0], mat1)\n",
    "        G_plus = exp_phi_plus.integrate(\n",
    "            \"(Ax+a)(Bx+b)'\",\n",
    "            A_mat=mat1_projected,\n",
    "            a_vec=vec1_projected,\n",
    "            B_mat=mat1_projected,\n",
    "            b_vec=vec1_projected,\n",
    "        )\n",
    "        G_minus = exp_phi_minus.integrate(\n",
    "            \"(Ax+a)(Bx+b)'\",\n",
    "            A_mat=mat1_projected,\n",
    "            a_vec=vec1_projected,\n",
    "            B_mat=mat1_projected,\n",
    "            b_vec=vec1_projected,\n",
    "        )\n",
    "        G_one = phi_one.integrate(\n",
    "            \"(Ax+a)(Bx+b)'\",\n",
    "            A_mat=mat1_projected,\n",
    "            a_vec=vec1_projected,\n",
    "            B_mat=mat1_projected,\n",
    "            b_vec=vec1_projected,\n",
    "        )\n",
    "        G = G_plus + G_minus - G_one\n",
    "        return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_G_i(cond, W[0], U[0], omega_star, p_x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test lower bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gaussian_toolbox import pdf, approximate_conditional, factor\n",
    "import numpy as np \n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "from matplotlib import pyplot as plt\n",
    "from jax import config, lax\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "Dy = 3\n",
    "Dx = 2\n",
    "R = 1\n",
    "Du = 1\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "M = jax.random.normal(subkey, shape=(1, Dy, Dx))\n",
    "b = jnp.array([jnp.zeros(Dy)])\n",
    "Sigma = jnp.array([jnp.eye(Dy)]) + .1\n",
    "mat = np.random.randn(Dy, Dy)\n",
    "Q, R = np.linalg.qr(mat)\n",
    "U = Q[:, :Du]\n",
    "W = jnp.array(np.random.randn(Du, Dx + 1))\n",
    "\n",
    "cond = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma, U=U, W=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "key, subkey = jax.random.split(key)\n",
    "y = jax.random.normal(key, (10, Dy))\n",
    "key, subkey = jax.random.split(key)\n",
    "mu = jax.random.normal(subkey, (1,Dx))\n",
    "key, subkey = jax.random.split(key)\n",
    "rand_mat = jax.random.uniform(subkey, (Dx, Dx))\n",
    "Sigma = jnp.array(jnp.eye(Dx) + jnp.dot(rand_mat, rand_mat.T))[None]\n",
    "px = pdf.GaussianPDF(mu=mu, Sigma=Sigma)\n",
    "p_x_tiled = pdf.GaussianPDF(mu=jnp.tile(mu, (y.shape[0], 1)), Sigma=jnp.tile(Sigma, (y.shape[0], 1, 1)))\n",
    "key, subkey = jax.random.split(key)\n",
    "x_samples = px.sample(subkey, num_samples)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_y_x, Lambda_y_x, ln_det_Sigma_y_x = cond.get_conditional_cov(x_samples, True)\n",
    "mu_y_x = cond.get_conditional_mu(x_samples)\n",
    "y_mu = y[:,None] - mu_y_x\n",
    "quadratic_term = - .5 * jnp.mean(jnp.einsum(\"abc,bcd,abd->ab\", y_mu, Lambda_y_x, y_mu), axis=1)\n",
    "log_det = ln_det_Sigma_y_x.mean()\n",
    "sampled_log_cond = quadratic_term - .5 * log_det - .5 * Dy * jnp.log(2 * jnp.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_log_cond2 = jnp.mean(cond(x_samples).evaluate_ln(y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounded_log_cond = jnp.empty((10,))\n",
    "integrate_log_conditional_y = jax.jit(cond.integrate_log_conditional_y)\n",
    "for i in range(10):\n",
    "    bounded_log_cond_i = cond.integrate_log_conditional_y(p_x=px, y=y[i:i+1])\n",
    "    bounded_log_cond = bounded_log_cond.at[i].set(bounded_log_cond_i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sampled_log_cond, sampled_log_cond2, \"o\")\n",
    "plt.plot(sampled_log_cond, bounded_log_cond, \"o\")\n",
    "plt.plot([-5, 0], [-5, 0], \"--\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not lower bound, but upper bound.\n",
    "\n",
    "Let's check the determinant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.integration_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = cond.W[:,0]\n",
    "w = cond.W[:,1:]\n",
    "omega_dagger = jnp.sqrt(px.integrate(\"(Ax+a)'(Bx+b)\", A_mat=w, a_vec=b, B_mat=w, b_vec=b))\n",
    "\n",
    "def k_tmp(omega_dagger, px):\n",
    "    Eh2 = px.integrate(\"(Ax+a)'(Bx+b)\", A_mat=w, a_vec=b, B_mat=w, b_vec=b)\n",
    "    return jnp.log(jnp.cosh(omega_dagger)) + .5 * jnp.tanh(omega_dagger) / omega_dagger * (Eh2 - omega_dagger ** 2)\n",
    "\n",
    "def lb_log_det_tmp(omega_dagger, px):\n",
    "    k_omega = k_tmp(omega_dagger, px)\n",
    "    lower_bound_log_det = cond.ln_det_Sigma + k_omega\n",
    "    return lower_bound_log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to integrate in toolbox\n",
    "def _get_omega_dagger(p_x: pdf.GaussianPDF, W_i: jnp.ndarray) -> jnp.ndarray:\n",
    "    b = W_i[None,:1]\n",
    "    w = W_i[None,1:]\n",
    "    omega_dagger = jnp.sqrt(p_x.integrate(\"(Ax+a)'(Bx+b)\", A_mat=w, a_vec=b, B_mat=w, b_vec=b))\n",
    "    return omega_dagger\n",
    "\n",
    "def k_func(p_x: pdf.GaussianPDF, W_i: jnp.ndarray, omega_dagger: jnp.ndarray):\n",
    "    b = W_i[None,:1]\n",
    "    w = W_i[None,1:]\n",
    "    Eh2 = p_x.integrate(\"(Ax+a)'(Bx+b)\", A_mat=w, a_vec=b, B_mat=w, b_vec=b)\n",
    "    return jnp.log(jnp.cosh(omega_dagger)) + .5 * jnp.tanh(omega_dagger) / omega_dagger * (Eh2 - omega_dagger ** 2)\n",
    "\n",
    "def get_lb_log_det(self, p_x: pdf.GaussianPDF):\n",
    "    omega_dagger = lax.stop_gradient(jax.vmap(lambda W: _get_omega_dagger(p_x=p_x, W_i=W), in_axes=(0,))(self.W))\n",
    "    k_omega = jax.vmap(lambda W, omega: k_func(p_x=p_x, W_i=W, omega_dagger=omega))(self.W, omega_dagger)\n",
    "    lower_bound_log_det = self.ln_det_Sigma + jnp.sum(k_omega, axis=0)\n",
    "    return lower_bound_log_det\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_range = jnp.linspace(.5 * omega_dagger,2 * omega_dagger, 100)\n",
    "plt.plot(omega_range, k_tmp(omega_range, px=px)[:,0])\n",
    "plt.plot(omega_range, jax.vmap(lambda omega: k_func(p_x=px, W_i=cond.W[0], omega_dagger=omega))(omega_range)[:,0], '--')\n",
    "plt.plot(omega_dagger, k_tmp(omega_dagger, px=px)[0], \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_log_det_tmp = lb_log_det_tmp(omega_range, px=px)\n",
    "lower_bound_log_det = cond.get_lb_log_det(p_x=px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(omega_range, lower_bound_log_det_tmp[:,0])\n",
    "plt.plot(omega_dagger, get_lb_log_det(cond, p_x=px), \"v\")\n",
    "plt.plot(omega_dagger, lb_log_det_tmp(omega_dagger, px), \"o\")\n",
    "plt.hlines(log_det, omega_range[0], omega_range[-1], linestyles=\"--\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Du, R]\n",
    "from jax import lax\n",
    "omega_dagger = jax.vmap(lambda W:_get_omega_dagger(p_x=p_x_tiled, W_i=W), out_axes=1)(cond.W)\n",
    "\n",
    "def _update_omega_star(cond, p_x: pdf.GaussianPDF, y: jnp.ndarray, W_i: jnp.ndarray, U_i: jnp.ndarray, omega_star: jnp.ndarray):\n",
    "    b = W_i[None,:1]\n",
    "    w = W_i[None,1:]\n",
    "    \n",
    "    g_1 = jnp.tanh(omega_star) / omega_star\n",
    "    nu_1 = - (jnp.tanh(omega_star) / omega_star)[:,None] * b * w\n",
    "    ln_beta_1 = - jnp.log(jnp.cosh(omega_star)) - .5 * jnp.tanh(omega_star) / omega_star * (b[0] ** 2 - omega_star ** 2)\n",
    "    phi_1 = p_x.hadamard(factor.OneRankFactor(v=jnp.tile(w, (omega_star.shape[0], 1)), g=g_1, nu=nu_1, ln_beta=ln_beta_1), update_full=True)\n",
    "    phi_plus = phi_1.hadamard(factor.LinearFactor(nu=w, ln_beta=b-jnp.log(2.)), update_full=True)\n",
    "    phi_minus = phi_1.hadamard(factor.LinearFactor(nu=-w, ln_beta=-b-jnp.log(2.)), update_full=True)\n",
    "\n",
    "    # Quartic integral\n",
    "\n",
    "    projected_M = jnp.einsum('acb,acd->abd', cond.L_inv, cond.M)\n",
    "    projected_yb = jnp.einsum('acb,ac->ab', cond.L_inv, y - cond.b)\n",
    "    U_projected_M = jnp.einsum('ab,cad->cbd', U_i[:,None], projected_M)\n",
    "    U_projected_yb = jnp.einsum('ab,ca->cb', U_i[:,None], projected_yb)\n",
    "    \n",
    "    quartic_1 = phi_1.integrate(\"(Ax+a)'(Bx+b)(Cx+c)'(Dx+d)\", A_mat=w, a_vec=b, B_mat=w, b_vec=b, \n",
    "                                C_mat=-U_projected_M, c_vec=U_projected_yb, D_mat=-U_projected_M, d_vec=U_projected_yb)\n",
    "    quartic_plus = phi_plus.integrate(\"(Ax+a)'(Bx+b)(Cx+c)'(Dx+d)\", A_mat=w, a_vec=b, B_mat=w, b_vec=b, \n",
    "                                      C_mat=-U_projected_M, c_vec=U_projected_yb, D_mat=-U_projected_M, d_vec=U_projected_yb)\n",
    "    quartic_minus = phi_minus.integrate(\"(Ax+a)'(Bx+b)(Cx+c)'(Dx+d)\", A_mat=w, a_vec=b, B_mat=w, b_vec=b, \n",
    "                                        C_mat=-U_projected_M, c_vec=U_projected_yb, D_mat=-U_projected_M, d_vec=U_projected_yb)\n",
    "\n",
    "    quartic_integral = - quartic_1 + quartic_plus + quartic_minus\n",
    "    # Quadratic integral\n",
    "    quadratic_1 = phi_1.integrate(\"(Ax+a)'(Bx+b)\", A_mat=-U_projected_M, a_vec=U_projected_yb, B_mat=-U_projected_M, b_vec=U_projected_yb)\n",
    "    quadratic_plus = phi_plus.integrate(\"(Ax+a)'(Bx+b)\", A_mat=-U_projected_M, a_vec=U_projected_yb, B_mat=-U_projected_M, b_vec=U_projected_yb)\n",
    "    quadratic_minus = phi_minus.integrate(\"(Ax+a)'(Bx+b)\", A_mat=-U_projected_M, a_vec=U_projected_yb, B_mat=-U_projected_M, b_vec=U_projected_yb)\n",
    "\n",
    "    quadratic_integral = - quadratic_1 + quadratic_plus + quadratic_minus\n",
    "\n",
    "    omega_star = jnp.sqrt(quartic_integral / quadratic_integral)[0]\n",
    "    return omega_star\n",
    "\n",
    "def _get_omega_star(cond, p_x: pdf.GaussianPDF, y: jnp.ndarray, W_i: jnp.ndarray, U_i: jnp.ndarray):\n",
    "    omega_star = _get_omega_dagger(p_x=p_x, W_i=W_i)\n",
    "    omega_dagger = omega_star + 1.\n",
    "    cond_func = lambda val: jnp.max(jnp.abs(val[0] - val[1])) > 1e-5\n",
    "    body_func = lambda val: (_update_omega_star(cond, p_x=p_x, y=y, W_i=W_i, U_i=U_i, omega_star=val[0]), val[0])\n",
    "    omega_star, _ = lax.while_loop(cond_func, body_func, (omega_star, omega_dagger))\n",
    "    return omega_star\n",
    "\n",
    "def get_lb_heteroscedastic_term_i(cond, p_x: pdf.GaussianPDF, y: jnp.ndarray, W_i: jnp.ndarray, U_i: jnp.ndarray):\n",
    "    omega_star = lax.stop_gradient(_get_omega_star(cond, p_x=p_x, y=y, W_i=W_i, U_i=U_i))\n",
    "    b = W_i[None,:1]\n",
    "    w = W_i[None,1:]\n",
    "    g_1 = jnp.tanh(omega_star) / omega_star\n",
    "    nu_1 = - (jnp.tanh(omega_star) / omega_star)[:,None] * b * w\n",
    "    ln_beta_1 = - jnp.log(jnp.cosh(omega_star)) - .5 * jnp.tanh(omega_star) / omega_star * (b ** 2 - omega_star ** 2)\n",
    "    phi_1 = p_x.hadamard(factor.OneRankFactor(v=jnp.tile(w, (omega_star.shape[0], 1)), g=g_1, nu=nu_1, ln_beta=ln_beta_1), update_full=True)\n",
    "    phi_plus = phi_1.hadamard(factor.LinearFactor(nu=w, ln_beta=b-jnp.log(2.)), update_full=True)\n",
    "    phi_minus = phi_1.hadamard(factor.LinearFactor(nu=-w, ln_beta=-b-jnp.log(2.)), update_full=True)\n",
    "    # Quadratic integral\n",
    "    projected_M = jnp.einsum('acb,acd->abd', cond.L_inv, cond.M)\n",
    "    projected_yb = jnp.einsum('acb,ac->ab', cond.L_inv, y - cond.b)\n",
    "    U_projected_M = jnp.einsum('ab,cad->cbd', U_i[:,None], projected_M)\n",
    "    U_projected_yb = jnp.einsum('ab,ca->cb', U_i[:,None], projected_yb)\n",
    "    quadratic_1 = phi_1.integrate(\"(Ax+a)'(Bx+b)\", A_mat=-U_projected_M, a_vec=U_projected_yb, B_mat=-U_projected_M, b_vec=U_projected_yb)\n",
    "    quadratic_plus = phi_plus.integrate(\"(Ax+a)'(Bx+b)\", A_mat=-U_projected_M, a_vec=U_projected_yb, B_mat=-U_projected_M, b_vec=U_projected_yb)\n",
    "    quadratic_minus = phi_minus.integrate(\"(Ax+a)'(Bx+b)\", A_mat=-U_projected_M, a_vec=U_projected_yb, B_mat=-U_projected_M, b_vec=U_projected_yb)\n",
    "\n",
    "    G_i = - quadratic_1 + quadratic_plus + quadratic_minus\n",
    "    return G_i\n",
    "\n",
    "def get_lb_quadratic_term(cond, p_x: pdf.GaussianPDF, y: jnp.ndarray):\n",
    "    projected_M = jnp.einsum('acb,acd->abd', cond.L_inv, cond.M)\n",
    "    projected_yb = jnp.einsum('acb,ac->ab', cond.L_inv, y - cond.b)\n",
    "    homoscedastic_term = p_x.integrate(\"(Ax+a)'(Bx+b)\", A_mat=-projected_M, a_vec=projected_yb, B_mat=-projected_M, b_vec=projected_yb)\n",
    "    get_lb_heteroscedastic_term = jnp.sum(jax.vmap(lambda W, U: get_lb_heteroscedastic_term_i(cond, p_x_tiled, y, W, U))(cond.W, cond.U.T), axis=0)\n",
    "    return homoscedastic_term - get_lb_heteroscedastic_term\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lb_quadratic_term(cond, p_x_tiled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_p_y(cond, p_x: pdf.GaussianPDF, y: jnp.ndarray):\n",
    "    lb_quadratic_term = get_lb_quadratic_term(cond, p_x, y)\n",
    "    lb_log_det = get_lb_log_det(cond, p_x)\n",
    "    lb_log_p_y = -.5 * (lb_quadratic_term + lb_log_det + Dy * jnp.log(2. * jnp.pi))[0]\n",
    "    return lb_log_p_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intgerate_jit_locally = jax.jit(get_log_p_y)\n",
    "%timeit intgerate_jit_locally(cond, p_x_tiled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate_jit = jax.jit(cond.integrate_log_conditional_y)\n",
    "%timeit integrate_jit(p_x_tiled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "x_samples = px.sample(key, 1000)\n",
    "log_p_y_sampled = jnp.mean(cond(x_samples[:,0]).evaluate_ln(y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intgerate_jit_locally(cond, p_x_tiled, y) - integrate_jit(p_x_tiled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log_p_y_sampled, lb_log_p_y, 'o')\n",
    "plt.plot(log_p_y_sampled, lb_log_p_y2, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond.U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_star = _get_omega_star(cond, p_x_tiled, y, cond.W[0], cond.U[:,0])\n",
    "omega_range = jnp.linspace(1e-3, 10., 100)[:,None]\n",
    "rhs = jax.vmap(lambda omega: _update_omega_star(cond, p_x=p_x_tiled, y=y, W_i=cond.W[0], U_i=cond.U[:,0], omega_star=omega))(omega_range)\n",
    "\n",
    "plt.plot(omega_range, rhs, \"-\")\n",
    "plt.plot([0,10], [0,10], \"--\")\n",
    "plt.plot(omega_star, omega_star, \"o\")\n",
    "plt.ylim((jnp.min(rhs), jnp.max(rhs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gaussian_toolbox import pdf, approximate_conditional, factor\n",
    "import numpy as np \n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "from matplotlib import pyplot as plt\n",
    "from jax import config, lax\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "Dy = 1\n",
    "Dx = 1\n",
    "R = 1\n",
    "Du = 1\n",
    "N = 1000\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "M = jax.random.normal(subkey, shape=(1, Dy, Dx))\n",
    "b = jnp.array([jnp.zeros(Dy)])\n",
    "Sigma_cond = .1 * jnp.array([jnp.eye(Dy)])\n",
    "mat = np.random.randn(Dy, Dy)\n",
    "Q, R = np.linalg.qr(mat)\n",
    "U = Q[:, :Du]\n",
    "W = jnp.array(np.random.randn(Du, Dx + 1))\n",
    "\n",
    "cond = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "y = jax.random.normal(key, (10, Dy))\n",
    "key, subkey = jax.random.split(key)\n",
    "mu = jax.random.normal(subkey, (1,Dx))\n",
    "key, subkey = jax.random.split(key)\n",
    "rand_mat = jax.random.uniform(subkey, (Dx, Dx))\n",
    "Sigma_x = 1. * jnp.array(jnp.eye(Dx) + jnp.dot(rand_mat, rand_mat.T))[None]\n",
    "px = pdf.GaussianPDF(mu=mu, Sigma=Sigma_x)\n",
    "key, subkey = jax.random.split(key)\n",
    "x_samples = px.sample(subkey, N)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "y = cond(x_samples).sample(subkey, 1)[0]\n",
    "p_x_tiled = pdf.GaussianPDF(mu=jnp.tile(mu, (y.shape[0], 1)), Sigma=jnp.tile(Sigma_x, (y.shape[0], 1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = jnp.linspace(-5, 5, 100)[:,None]\n",
    "plt.plot(x_samples, y, '.')\n",
    "plt.plot(x_range, cond(x_range).mu)\n",
    "plt.fill_between(x_range[:,0], cond(x_range).mu[:,0] - jnp.sqrt(cond(x_range).Sigma[:,0,0]), cond(x_range).mu[:,0] + jnp.sqrt(cond(x_range).Sigma[:,0,0]), alpha=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    W = params['W']\n",
    "    cond = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W)\n",
    "    return -jnp.sum(cond.integrate_log_conditional_y(p_x_tiled, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaxopt\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "solver = jaxopt.ScipyMinimize(method='CG', fun=objective)\n",
    "res = solver.run(init_params={'W': 1e-2 * jax.random.normal(subkey, W.shape)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.sign(cond.W), cond.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "objective_results = []\n",
    "for i in range(100):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    res = solver.run(init_params={'W': jax.random.normal(subkey, W.shape)})\n",
    "    results.append(res.params)\n",
    "    objective_results.append(res.state.fun_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.nanargmin(jnp.array(objective_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opt = results[jnp.nanargmin(jnp.array(objective_results))]\n",
    "cond_fit = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=res_opt['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = jnp.linspace(-5, 5, 100)[:,None]\n",
    "plt.plot(x_samples, y, '.')\n",
    "plt.plot(x_range, cond(x_range).mu)\n",
    "plt.fill_between(x_range[:,0], cond(x_range).mu[:,0] - jnp.sqrt(cond(x_range).Sigma[:,0,0]), cond(x_range).mu[:,0] + jnp.sqrt(cond(x_range).Sigma[:,0,0]), alpha=.2)\n",
    "plt.plot(x_range, cond_fit(x_range).mu)\n",
    "plt.fill_between(x_range[:,0], cond_fit(x_range).mu[:,0] - jnp.sqrt(cond_fit(x_range).Sigma[:,0,0]), \n",
    "                 cond_fit(x_range).mu[:,0] + jnp.sqrt(cond_fit(x_range).Sigma[:,0,0]), alpha=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_sample(params, key):\n",
    "    W = params['W']\n",
    "    key, subkey = jax.random.split(key)\n",
    "    cond_tmp = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W)\n",
    "    x_samples = px.sample(subkey, 1000)[:,0]\n",
    "    return -jnp.sum(jnp.mean(cond_tmp(x_samples).evaluate_ln(y), axis=0)), key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_range = jnp.linspace(-4, 4, 100)\n",
    "W_range = jnp.linspace(-4, 4, 100)\n",
    "mesh = jnp.meshgrid(b_range, W_range)\n",
    "W_mesh = jnp.stack([mesh[0].flatten(), mesh[1].flatten()], axis=-1)\n",
    "\n",
    "objective_arr = []\n",
    "objective_sample_arr = []\n",
    "\n",
    "objective_jit = jax.jit(objective)\n",
    "objective_sample_jit = jax.jit(objective_sample)\n",
    "\n",
    "for idx in range(W_mesh.shape[0]):\n",
    "    objective_arr.append(objective_jit({'W': W_mesh[idx:idx+1]}))\n",
    "    val, key = objective_sample_jit({'W': W_mesh[idx:idx+1]}, key)\n",
    "    objective_sample_arr.append(val)\n",
    "#cond_tmp = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W[idx:idx+1])\n",
    "#cond_fit = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=res_opt['W'])\n",
    "objective_arr = jnp.array(objective_arr).reshape(mesh[0].shape)\n",
    "objective_sample_arr = jnp.array(objective_sample_arr).reshape(mesh[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolor(mesh[0], mesh[1], objective_arr)\n",
    "plt.plot(res_opt['W'][0,0], res_opt['W'][0,1], 'r*')\n",
    "plt.plot(W[0,0], W[0,1], 'bs')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolor(mesh[0], mesh[1], objective_sample_arr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gaussian_toolbox import pdf, approximate_conditional, factor\n",
    "import numpy as np \n",
    "from jax import numpy as jnp\n",
    "import jax\n",
    "from matplotlib import pyplot as plt\n",
    "from jax import config, lax\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "Dy = 1\n",
    "Dx = 1\n",
    "R = 1\n",
    "Du = 1\n",
    "N = 100\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "M = jax.random.normal(subkey, shape=(1, Dy, Dx))\n",
    "b = jnp.array([jnp.zeros(Dy)])\n",
    "Sigma_cond = .1 * jnp.array([jnp.eye(Dy)])\n",
    "mat = np.random.randn(Dy, Dy)\n",
    "Q, R = np.linalg.qr(mat)\n",
    "U = Q[:, :Du]\n",
    "W = jnp.array(np.random.randn(Du, Dx + 1))\n",
    "\n",
    "cond = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "y = jax.random.normal(key, (10, Dy))\n",
    "key, subkey = jax.random.split(key)\n",
    "mu = jax.random.normal(subkey, (N, Dx))\n",
    "key, subkey = jax.random.split(key)\n",
    "rand_mat = jax.random.uniform(subkey, (Dx, Dx))\n",
    "Sigma_x = 1. * jnp.array(jnp.eye(Dx) + jnp.dot(rand_mat, rand_mat.T))[None]\n",
    "px = pdf.GaussianPDF(mu=mu, Sigma=Sigma_x)\n",
    "key, subkey = jax.random.split(key)\n",
    "x_samples = px.sample(subkey, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "y = cond(x_samples).sample(subkey, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = jnp.linspace(-5, 5, 100)[:,None]\n",
    "plt.plot(x_samples, y, '.')\n",
    "plt.plot(x_range, cond(x_range).mu)\n",
    "plt.fill_between(x_range[:,0], cond(x_range).mu[:,0] - jnp.sqrt(cond(x_range).Sigma[:,0,0]), cond(x_range).mu[:,0] + jnp.sqrt(cond(x_range).Sigma[:,0,0]), alpha=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    W = params['W']\n",
    "    cond = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W)\n",
    "    return -jnp.sum(cond.integrate_log_conditional_y(px, y))\n",
    "\n",
    "import jaxopt\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "solver = jaxopt.ScipyMinimize(method='CG', fun=objective)\n",
    "res = solver.run(init_params={'W': 1e-2 * jax.random.normal(subkey, W.shape)})\n",
    "cond_fit = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=res.params['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = jnp.linspace(-5, 5, 100)[:,None]\n",
    "plt.plot(x_samples, y, 'k.', label='data')\n",
    "#plt.plot(x_range, cond(x_range).mu)\n",
    "plt.fill_between(x_range[:,0], cond(x_range).mu[:,0] - jnp.sqrt(cond(x_range).Sigma[:,0,0]), cond(x_range).mu[:,0] + jnp.sqrt(cond(x_range).Sigma[:,0,0]), alpha=.2, label='true')\n",
    "#plt.plot(x_range, cond_fit(x_range).mu)\n",
    "plt.fill_between(x_range[:,0], cond_fit(x_range).mu[:,0] - jnp.sqrt(cond_fit(x_range).Sigma[:,0,0]), \n",
    "                 cond_fit(x_range).mu[:,0] + jnp.sqrt(cond_fit(x_range).Sigma[:,0,0]), alpha=.2, label='fit')\n",
    "plt.plot(x_range, px.evaluate(x_range).T - 6, 'k', alpha=.5, label='p(x)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(['data', 'true', 'fit', 'p(x)'])\n",
    "plt.title('High variance of x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples[:,i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_sample(params, key):\n",
    "    W = params['W']\n",
    "    key, subkey = jax.random.split(key)\n",
    "    cond_tmp = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W)\n",
    "    x_samples = px.sample(subkey, 1000)\n",
    "    log_likelihood = 0\n",
    "    log_likelihood = lax.fori_loop(0, 100, lambda i, log_likelihood: log_likelihood + jnp.mean(cond_tmp(x_samples[:,i]).evaluate_ln(y[i][None])), log_likelihood)\n",
    "    return -log_likelihood, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "cond_tmp = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W)\n",
    "x_samples = px.sample(subkey, 1000)\n",
    "i = 99\n",
    "jnp.mean(cond_tmp(x_samples[:,i]).evaluate_ln(y[i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_range = jnp.linspace(-4, 4, 100)\n",
    "W_range = jnp.linspace(-4, 4, 100)\n",
    "mesh = jnp.meshgrid(b_range, W_range)\n",
    "W_mesh = jnp.stack([mesh[0].flatten(), mesh[1].flatten()], axis=-1)\n",
    "\n",
    "objective_arr = []\n",
    "objective_sample_arr = []\n",
    "\n",
    "objective_jit = jax.jit(objective)\n",
    "objective_sample_jit = jax.jit(objective_sample)\n",
    "\n",
    "for idx in range(W_mesh.shape[0]):\n",
    "    objective_arr.append(objective_jit({'W': W_mesh[idx:idx+1]}))\n",
    "    val, key = objective_sample_jit({'W': W_mesh[idx:idx+1]}, key)\n",
    "    objective_sample_arr.append(val)\n",
    "#cond_tmp = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=W[idx:idx+1])\n",
    "#cond_fit = approximate_conditional.FullHCCovGaussianConditional(M=M, b=b, Sigma=Sigma_cond, U=U, W=res_opt['W'])\n",
    "objective_arr = jnp.array(objective_arr).reshape(mesh[0].shape)\n",
    "objective_sample_arr = jnp.array(objective_sample_arr).reshape(mesh[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolor(mesh[0], mesh[1], objective_arr)\n",
    "plt.plot(res.params['W'][0,0], res.params['W'][0,1], 'r*', label='fit')\n",
    "plt.plot(W[0,0], W[0,1], 'bs', label='true')\n",
    "plt.legend()\n",
    "plt.xlabel('b')\n",
    "plt.ylabel('W')\n",
    "plt.colorbar()\n",
    "plt.title('lb loglikelihood')\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolor(mesh[0], mesh[1], objective_sample_arr)\n",
    "plt.colorbar()\n",
    "plt.title('sampled log likelihood')\n",
    "plt.xlabel('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective({\"W\": cond.W})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective({\"W\": cond_fit.W})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hkf_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
