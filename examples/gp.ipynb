{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian processes\n",
    "\n",
    "Another model class, where Gaussian manipulation is heavily used are Gaussian processes (GPs). Hence also here `GT` can excel.\n",
    "\n",
    "*Disclaimer*: As for the state-space models, this is just a small example to show how `GT` can be used. It cannot compete with functionalities of specialized GP toolboxes like [GPFlow](https://www.gpflow.org/), or [GPJax](https://github.com/thomaspinder/GPJax).\n",
    "\n",
    "**Definition**: *A Gaussian process is a collection of random variables, any Gaussian process finite number of which have a joint Gaussian distribution.* [\\[Rasmussen & Williams, 2006\\]](https://gaussianprocess.org/gpml/chapters/RW2.pdf)\n",
    "\n",
    "Below we demonstrate, how a `GT` based suite can implement very efficiently GP regression for exact and sparse [\\[Tisias, 2009\\]](http://proceedings.mlr.press/v5/titsias09a/titsias09a.pdf). We just defined prior, and likelihood objects based on the Gaussian operations defined previously. The objectives (marginal likelihood for exact and evidence lower bound for sparse GPs) can be well expressed in Gaussian integrals, and then used for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from gaussian_toolbox.gaussian_process import kernel, prior, likelihood, model\n",
    "from jax import numpy as jnp\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact GP: 1D Examples\n",
    "\n",
    "First we generate some simple 1D dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "num_points = 100\n",
    "sigma_y = .1\n",
    "x = jnp.array(np.sort(2 * np.pi * np.random.rand(num_points, 1), axis=0))\n",
    "x_star = jnp.array([jnp.arange(0, 2 * jnp.pi, .1)]).T\n",
    "y = jnp.array(np.cos(2 * x) + sigma_y * np.random.randn(num_points, 1)) + 1.\n",
    "y = y.flatten()\n",
    "plt.plot(x , y, '.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact GP regression\n",
    "\n",
    "We create a GP prior with corresponding kernel, and likelihood. This two are combined into a GP regression model, that then can be inferred (with learning the hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and do inference\n",
    "k_func = kernel.Matern32()\n",
    "gp_prior = prior.GP_Prior(k_func)\n",
    "lk = likelihood.GaussianLikelihood()\n",
    "gp_model = model.GPRegressionModel(gp_prior, lk)\n",
    "gp_model.infer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "prior_x = gp_prior.get_density(x_star)\n",
    "predictive_gp = gp_model.predict_gp(x_star, True)\n",
    "predictive_data = gp_model.predict_data(x_star, True)\n",
    "\n",
    "plt.fill_between(x_star[:,0], prior_x.mu[0] - prior_x.Sigma[0].diagonal(), prior_x.mu[0] + prior_x.Sigma[0].diagonal(), alpha=.1, label=\"GP prior\")\n",
    "plt.fill_between(x_star[:,0], predictive_gp.mu[:,0] - np.sqrt(predictive_gp.Sigma[:,0,0]), predictive_gp .mu[:,0] + np.sqrt(predictive_gp.Sigma[:,0,0]), alpha=.5, label=\"GP posterior\")\n",
    "plt.fill_between(x_star[:,0], predictive_data.mu[:,0] - np.sqrt(predictive_data.Sigma[:,0,0]), predictive_data.mu[:,0] + np.sqrt(predictive_data.Sigma[:,0,0]), alpha=.5, label=\"Data prediction\")\n",
    "plt.plot(x , y, 'k.', label=\"Data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse GP regression\n",
    "\n",
    "Same we can do for sparse GPs. The difference to exact GPs is that we work with a *sparse likelihood* that is defined as follows\n",
    "\n",
    "$$\n",
    "\\ln p(y\\vert g_u) = \\mathbb{E}_{g\\vert g_u}\\left[\\ln p(y\\vert g)\\right],\n",
    "$$\n",
    "where the expectations is over the conditional prior $p(g\\vert g_u)$, where $g_u$ are the function values at a set of so called *inducing points* $X_u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and do inference\n",
    "num_inducing_points = 20\n",
    "k_func = kernel.Matern32()\n",
    "Xu = 2 * jnp.pi * jnp.array(np.random.rand(num_inducing_points,1))\n",
    "sgp_prior = prior.SparseGP_Prior(k_func, Xu, optimize_Xu=True)\n",
    "lk = likelihood.GaussianLikelihood()\n",
    "sgp_model = model.SGPRegressionModel(sgp_prior, lk)\n",
    "sgp_model.infer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "prior_x = sgp_prior.get_density(x_star)\n",
    "predictive_gp = sgp_model.predict_gp(x_star, True)\n",
    "predictive_data = sgp_model.predict_data(x_star, True)\n",
    "\n",
    "plt.fill_between(x_star[:,0], prior_x.mu[0] - prior_x.Sigma[0].diagonal(), prior_x.mu[0] + prior_x.Sigma[0].diagonal(), alpha=.1, label=\"GP prior\")\n",
    "plt.fill_between(x_star[:,0], predictive_gp.mu[:,0] - np.sqrt(predictive_gp.Sigma[:,0,0]), predictive_gp.mu[:,0] + np.sqrt(predictive_gp.Sigma[:,0,0]), alpha=.5, label=\"GP posterior\")\n",
    "plt.fill_between(x_star[:,0], predictive_data.mu[:,0] - np.sqrt(predictive_data.Sigma[:,0,0]), predictive_data.mu[:,0] + np.sqrt(predictive_data.Sigma[:,0,0]), alpha=.5, label=\"Data prediction\")\n",
    "plt.plot(x , y, 'k.', label=\"Data\")\n",
    "plt.plot(sgp_model.prior.Xu[:,0], sgp_model.posterior_density.mu[0], 'C3s', label=\"Inducing points\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = [[-1,1], [-1, 1]]\n",
    "num_points_star = 40\n",
    "num_points = 100\n",
    "sigma_y = .1\n",
    "x_range, y_range = jnp.linspace(limits[0][0], limits[0][1], num_points_star), jnp.linspace(limits[1][0], limits[1][1], num_points_star)\n",
    "x_grid, y_grid = np.meshgrid(x_range, y_range)\n",
    "x_star = jnp.vstack([x_grid.flatten(), y_grid.flatten()]).T\n",
    "true_func = lambda x: jnp.cos(2 * np.pi * x[:,0]) * jnp.sin(x[:,1])\n",
    "x = np.random.rand(num_points, 2)\n",
    "x[:,0] = (limits[0][1] - limits[0][0]) * x[:,0] + limits[0][0]\n",
    "x[:,1] = (limits[1][1] - limits[1][0]) * x[:,1] + limits[1][0]\n",
    "x = jnp.array(x)\n",
    "y = true_func(x) + sigma_y * np.random.randn(num_points)\n",
    "plt.pcolor(x_range, y_range, true_func(x_star).reshape((num_points_star, num_points_star)))\n",
    "plt.plot(x[:,0], x[:,1], '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact GP regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_func = kernel.Matern32()\n",
    "gp_prior = prior.GP_Prior(k_func)\n",
    "lk = likelihood.GaussianLikelihood()\n",
    "gp_model = model.GPRegressionModel(gp_prior, lk)\n",
    "gp_model.infer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_x = gp_prior.get_density(x_star)\n",
    "predictive_gp = gp_model.predict_gp(x_star, True)\n",
    "predictive_data = gp_model.predict_data(x_star, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.pcolor(x_range, y_range, predictive_data.mu[:,0].reshape((num_points_star, num_points_star)))\n",
    "plt.subplot(122)\n",
    "plt.pcolor(x_range, y_range, predictive_data.Sigma[:,0,0].reshape((num_points_star, num_points_star)))\n",
    "plt.plot(x[:,0], x[:,1], '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse GP regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inducing_points = 20\n",
    "Xu = np.random.rand(num_inducing_points,2)\n",
    "Xu[:,0] = (limits[0][1] - limits[0][0]) * Xu[:,0] + limits[0][0]\n",
    "Xu[:,1] = (limits[1][1] - limits[1][0]) * Xu[:,1] + limits[1][0]\n",
    "Xu = jnp.array(Xu)\n",
    "k_func = kernel.RBF()\n",
    "sgp_prior = prior.SparseGP_Prior(k_func, Xu, optimize_Xu=True)\n",
    "lk = likelihood.GaussianLikelihood()\n",
    "sgp_model = model.SGPRegressionModel(sgp_prior, lk)\n",
    "sgp_model.infer(x, y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_x = sgp_prior.get_density(x_star)\n",
    "predictive_gp = sgp_model.predict_gp(x_star, True)\n",
    "predictive_data = sgp_model.predict_data(x_star, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.pcolor(x_range, y_range, predictive_data.mu[:,0].reshape((num_points_star, num_points_star)))\n",
    "plt.plot(Xu[:,0], Xu[:,1], 'w.')\n",
    "plt.plot(sgp_model.prior.Xu[:,0], sgp_model.prior.Xu[:,1], 'C3s')\n",
    "plt.plot(x[:,0], x[:,1], 'k.')\n",
    "plt.subplot(122)\n",
    "plt.pcolor(x_range, y_range, predictive_data.Sigma[:,0,0].reshape((num_points_star, num_points_star)))\n",
    "plt.plot(x[:,0], x[:,1], 'k.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('gaussian_toolbox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "782cd5dadb26a54d425c88a99e91aaf22c15a8b7b364f1b6867d338206b7ed04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
